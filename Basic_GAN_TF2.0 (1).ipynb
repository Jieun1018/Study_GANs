{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "neural-perth",
   "metadata": {},
   "source": [
    "## Basic_GAN\n",
    "\n",
    "ref: https://github.com/tensorflow/docs-l10n/blob/master/site/ko/tutorials/generative/dcgan.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "peaceful-melbourne",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imageio\n",
      "  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from imageio) (1.19.5)\n",
      "Requirement already satisfied: pillow in c:\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from imageio) (8.1.2)\n",
      "Installing collected packages: imageio\n",
      "Successfully installed imageio-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "experienced-performer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from tensorflow.keras import layers\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abroad-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터셋 로딩 및 준비\n",
    "\n",
    "\n",
    "(train_images, train_labels), (_, _) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriented-ambassador",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32')\n",
    "train_images = (train_images - 127.5) / 127.5 # 이미지를 [-1, 1]로 정규화합니다.\n",
    "\n",
    "\n",
    "BUFFER_SIZE = 60000\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "# 데이터 배치를 만들고 섞습니다.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "working-bookmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator\n",
    "\n",
    "def make_generator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Reshape((7, 7, 256)))\n",
    "    assert model.output_shape == (None, 7, 7, 256) # 주목: 배치사이즈로 None이 주어집니다.\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 7, 7, 128)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
    "    assert model.output_shape == (None, 14, 14, 64)\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU())\n",
    "\n",
    "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
    "    assert model.output_shape == (None, 28, 28, 1)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "related-physics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x218d6932828>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "\n",
    "generator = make_generator_model()\n",
    "\n",
    "noise = tf.random.normal([1, 100])\n",
    "generated_image = generator(noise, training=False)\n",
    "\n",
    "plt.imshow(generated_image[0, :, :, 0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "threaded-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "#discriminator\n",
    "\n",
    "def make_discriminator_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same',\n",
    "                                     input_shape=[28, 28, 1]))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
    "    model.add(layers.LeakyReLU())\n",
    "    model.add(layers.Dropout(0.3))\n",
    "\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "extraordinary-madrid",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.00390459]], shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "\n",
    "discriminator = make_discriminator_model()\n",
    "decision = discriminator(generated_image)\n",
    "print (decision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "exterior-funeral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function & optimizer\n",
    "\n",
    "# 이 메서드는 크로스 엔트로피 손실함수 (cross entropy loss)를 계산하기 위해 헬퍼 (helper) 함수를 반환합니다.\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "political-compensation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generator loss fuc\n",
    "def generator_loss(fake_output):\n",
    "    return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "duplicate-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer,\n",
    "                                 discriminator_optimizer=discriminator_optimizer,\n",
    "                                 generator=generator,\n",
    "                                 discriminator=discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "distinguished-cemetery",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "noise_dim = 100\n",
    "num_examples_to_generate = 16\n",
    "\n",
    "# 이 시드를 시간이 지나도 재활용하겠습니다. \n",
    "# (GIF 애니메이션에서 진전 내용을 시각화하는데 쉽기 때문입니다.) \n",
    "seed = tf.random.normal([num_examples_to_generate, noise_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "durable-rental",
   "metadata": {},
   "outputs": [],
   "source": [
    "# `tf.function`이 어떻게 사용되는지 주목해 주세요.\n",
    "# 이 데코레이터는 함수를 \"컴파일\"합니다.\n",
    "@tf.function\n",
    "def train_step(images):\n",
    "    noise = tf.random.normal([BATCH_SIZE, noise_dim])\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "      generated_images = generator(noise, training=True)\n",
    "\n",
    "      real_output = discriminator(images, training=True)\n",
    "      fake_output = discriminator(generated_images, training=True)\n",
    "\n",
    "      gen_loss = generator_loss(fake_output)\n",
    "      disc_loss = discriminator_loss(real_output, fake_output)\n",
    "\n",
    "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "commercial-message",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "\n",
    "    for image_batch in dataset:\n",
    "      train_step(image_batch)\n",
    "\n",
    "    # GIF를 위한 이미지를 바로 생성합니다.\n",
    "    display.clear_output(wait=True)\n",
    "    generate_and_save_images(generator,\n",
    "                             epoch + 1,\n",
    "                             seed)\n",
    "\n",
    "    # 15 에포크가 지날 때마다 모델을 저장합니다.\n",
    "    if (epoch + 1) % 15 == 0:\n",
    "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
    "    \n",
    "    # print (' 에포크 {} 에서 걸린 시간은 {} 초 입니다'.format(epoch +1, time.time()-start))\n",
    "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
    "    #임의 삽입\n",
    "    %%time\n",
    "    train(train_dataset, EPOCHS)\n",
    "    #\n",
    "  # 마지막 에포크가 끝난 후 생성합니다.\n",
    "  display.clear_output(wait=True)\n",
    "  generate_and_save_images(generator,\n",
    "                           epochs,\n",
    "                           seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "premier-permit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_save_images(model, epoch, test_input):\n",
    "  # `training`이 False로 맞춰진 것을 주목하세요.\n",
    "  # 이렇게 하면 (배치정규화를 포함하여) 모든 층들이 추론 모드로 실행됩니다. \n",
    "  predictions = model(test_input, training=False)\n",
    "\n",
    "  fig = plt.figure(figsize=(4,4))\n",
    "\n",
    "  for i in range(predictions.shape[0]):\n",
    "      plt.subplot(4, 4, i+1)\n",
    "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
    "      plt.axis('off')\n",
    "\n",
    "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "seasonal-plate",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "in converted code:\n\n    <ipython-input-15-7edc6b37d517>:14 train_step  *\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    NameError: name 'discriminator_loss' is not defined\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-bd83db03824b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(dataset, epochs)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m       \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# GIF를 위한 이미지를 바로 생성합니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    492\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 494\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1820\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1822\u001b[1;33m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1823\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2148\u001b[0m         \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2149\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgraph_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2150\u001b[1;33m           \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2151\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2039\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2040\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2041\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2042\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2043\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    913\u001b[0m                                           converted_func)\n\u001b[0;32m    914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m       \u001b[0mfunc_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[1;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[1;34m(*args, **kwds)\u001b[0m\n\u001b[0;32m    356\u001b[0m         \u001b[1;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    357\u001b[0m         \u001b[1;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 358\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    359\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mref\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    903\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    904\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 905\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    906\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    907\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: in converted code:\n\n    <ipython-input-15-7edc6b37d517>:14 train_step  *\n        disc_loss = discriminator_loss(real_output, fake_output)\n\n    NameError: name 'discriminator_loss' is not defined\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "#train(train_dataset, EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "nominated-puppy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.InitializationOnlyStatus at 0x218e5936fd0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "warming-toyota",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 에포크 숫자를 사용하여 하나의 이미지를 보여줍니다.\n",
    "def display_image(epoch_no):\n",
    "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch_no))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "joined-azerbaijan",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'image_at_epoch_0050.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-7d0477526f8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-36-d6784bdf3c53>\u001b[0m in \u001b[0;36mdisplay_image\u001b[1;34m(epoch_no)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 에포크 숫자를 사용하여 하나의 이미지를 보여줍니다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdisplay_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mPIL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'image_at_epoch_{:04d}.png'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_no\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2902\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2903\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2904\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2905\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2906\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'image_at_epoch_0050.png'"
     ]
    }
   ],
   "source": [
    "display_image(EPOCHS)\n",
    "\n",
    "#file path 문제?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "concrete-johnson",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-880e85e12649>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m   \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m   \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'filename' is not defined"
     ]
    }
   ],
   "source": [
    "anim_file = 'dcgan.gif'\n",
    "\n",
    "with imageio.get_writer(anim_file, mode='I') as writer:\n",
    "  filenames = glob.glob('image*.png')\n",
    "  filenames = sorted(filenames)\n",
    "  last = -1\n",
    "  for i,filename in enumerate(filenames):\n",
    "    frame = 2*(i**0.5)\n",
    "    if round(frame) > round(last):\n",
    "      last = frame\n",
    "    else:\n",
    "      continue\n",
    "    image = imageio.imread(filename)\n",
    "    writer.append_data(image)\n",
    "  image = imageio.imread(filename)\n",
    "  writer.append_data(image)\n",
    "\n",
    "import IPython\n",
    "if IPython.version_info > (6,2,0,''):\n",
    "  display.Image(filename=anim_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prime-texas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
